<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Primary Meta Tags -->
    <title>Utah Elementary Teacher Training Assistant - Documentation</title>
    <meta name="title" content="Utah Elementary Teacher Training Assistant - Documentation">
    <meta name="description" content="Comprehensive guide to building AI-powered teacher training systems using LLMs, from fundamentals to implementation.">
    <meta name="keywords" content="AI, teacher training, education, LLM, machine learning, pedagogical AI, educational technology, teaching simulation">
    <meta name="author" content="AI Teacher Training Project">
    <meta name="robots" content="index, follow">

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://uvu-ai-innovate.github.io/UTAH-TTA/">
    <meta property="og:title" content="Utah Elementary Teacher Training Assistant - Documentation">
    <meta property="og:description" content="Comprehensive guide to building AI-powered teacher training systems using LLMs, from fundamentals to implementation.">
    <meta property="og:image" content="https://uvu-ai-innovate.github.io/UTAH-TTA/assets/social-preview.png">

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://uvu-ai-innovate.github.io/UTAH-TTA/">
    <meta property="twitter:title" content="Utah Elementary Teacher Training Assistant - Documentation">
    <meta property="twitter:description" content="Comprehensive guide to building AI-powered teacher training systems using LLMs, from fundamentals to implementation.">
    <meta property="twitter:image" content="https://uvu-ai-innovate.github.io/UTAH-TTA/assets/social-preview.png">

    <!-- Favicon -->
    <link rel="apple-touch-icon" sizes="180x180" href="/assets/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon-16x16.png">
    <link rel="manifest" href="/assets/site.webmanifest">

    <!-- Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Fira+Code:wght@400;500&display=swap" rel="stylesheet">

    <!-- Theme Color for Mobile -->
    <meta name="theme-color" content="#2c3e50">

    <style>
        /* Update font family to use Inter */
        
        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            color: #333;
            background-color: #f8f9fa;
        }
        /* Add smooth scrolling to the whole page */
        
        html {
            scroll-behavior: smooth;
        }
        /* Add loading optimization */
        
        img {
            loading: lazy;
        }
        
        h1,
        h2,
        h3 {
            color: #2c3e50;
            margin-top: 1.5em;
            scroll-margin-top: 80px;
            /* For smooth scrolling to anchors */
        }
        
        pre {
            background-color: #2d2d2d;
            color: #f8f8f2;
            padding: 20px;
            border-radius: 8px;
            overflow-x: auto;
            margin: 20px 0;
            font-size: 0.9em;
            line-height: 1.5;
        }
        
        code {
            font-family: 'Fira Code', 'Courier New', monospace;
            background-color: #2d2d2d;
            color: #f8f8f2;
            padding: 3px 6px;
            border-radius: 4px;
        }
        
        .section {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            margin-bottom: 30px;
        }
        
        .note,
        .definition,
        .example,
        .warning {
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
        }
        
        img {
            max-width: 100%;
            height: auto;
        }
        /* New navigation styles */
        
        .nav-container {
            background: white;
            padding: 15px 20px;
            border-radius: 10px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            margin-bottom: 30px;
            position: sticky;
            top: 20px;
            z-index: 1000;
        }
        
        .nav-toggle {
            display: none;
            padding: 10px;
            background: #2c3e50;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
        }
        
        .toc {
            background: white;
            padding: 25px;
            border-radius: 10px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            position: sticky;
            top: 100px;
            max-height: calc(100vh - 150px);
            overflow-y: auto;
        }
        
        .toc ul {
            list-style-type: none;
            padding-left: 20px;
        }
        
        .toc li {
            margin: 8px 0;
        }
        
        .toc a {
            color: #2c3e50;
            text-decoration: none;
        }
        
        .toc a:hover {
            color: #3498db;
        }
        /* Back to top button */
        
        .back-to-top {
            position: fixed;
            bottom: 30px;
            right: 30px;
            background: #2c3e50;
            color: white;
            padding: 12px 20px;
            border-radius: 30px;
            text-decoration: none;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.2);
            transition: all 0.3s ease;
            opacity: 0;
            visibility: hidden;
        }
        
        .back-to-top.visible {
            opacity: 1;
            visibility: visible;
        }
        
        .back-to-top:hover {
            background: #3498db;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
        }
        /* Responsive design */
        
        @media (max-width: 768px) {
            .nav-toggle {
                display: block;
            }
            .toc {
                display: none;
            }
            .toc.show {
                display: block;
            }
        }
        /* Diagram styles */
        
        .diagram {
            background: white;
            padding: 30px;
            margin: 30px 0;
            border-radius: 10px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }
        
        .diagram-container {
            gap: 20px;
            padding: 20px;
        }
        
        .component {
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            transition: transform 0.2s, box-shadow 0.2s;
        }
        
        .component:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.15);
        }
        
        .arrow {
            position: relative;
            width: 50px;
            height: 2px;
            background: #666;
            margin: 10px;
        }
        
        .arrow::after {
            content: '';
            position: absolute;
            right: -5px;
            top: -4px;
            width: 10px;
            height: 10px;
            border-top: 2px solid #666;
            border-right: 2px solid #666;
            transform: rotate(45deg);
        }
        
        .flow-diagram {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 20px;
            margin: 20px 0;
        }
        
        .system-component {
            background: #e3f2fd;
            border: 2px solid #1976d2;
            padding: 15px;
            border-radius: 8px;
            text-align: center;
        }
        
        .data-flow {
            border: 2px solid #2e7d32;
            background: #e8f5e9;
        }
        
        .user-component {
            border: 2px solid #c62828;
            background: #ffebee;
        }
        
        .llm-component {
            border: 2px solid #6a1b9a;
            background: #f3e5f5;
        }
        
        .memory-component {
            border: 2px solid #ef6c00;
            background: #fff3e0;
        }
        
        .connection-line {
            position: relative;
            padding: 10px;
            text-align: center;
            color: #666;
        }
        /* Layout improvements */
        
        .main-content {
            display: grid;
            grid-template-columns: minmax(250px, 1fr) minmax(600px, 3fr);
            gap: 30px;
            margin-top: 20px;
        }
        
        @media (max-width: 1024px) {
            .main-content {
                grid-template-columns: 1fr;
            }
        }
        
        .content-section {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            margin-bottom: 30px;
        }
        /* Typography improvements */
        
        h1 {
            font-size: 2.5em;
        }
        
        h2 {
            font-size: 2em;
        }
        
        h3 {
            font-size: 1.5em;
        }
        
        h4 {
            font-size: 1.25em;
        }
        /* List improvements */
        
        ul,
        ol {
            padding-left: 1.5em;
            margin: 1em 0;
        }
        
        li {
            margin: 0.5em 0;
        }
        /* Print styles */
        
        @media print {
            body {
                background: white;
                color: black;
            }
            .nav-container,
            .back-to-top {
                display: none;
            }
            .section {
                break-inside: avoid;
                page-break-inside: avoid;
            }
        }
    </style>
</head>

<body>
    <div class="nav-container">
        <button class="nav-toggle" onclick="toggleTOC()">☰ Table of Contents</button>
    </div>

    <div class="main-content">
        <aside class="sidebar">
            <div class="toc">
                <h2>Table of Contents</h2>
                <ul>
                    <li><a href="#llm-fundamentals">1. Understanding Large Language Models (LLMs)</a>
                        <ul>
                            <li><a href="#what-are-llms">1.1 What are LLMs?</a></li>
                            <li><a href="#llm-capabilities">1.2 LLM Capabilities and Limitations</a></li>
                            <li><a href="#local-vs-api">1.3 Local LLMs vs API Services</a></li>
                        </ul>
                    </li>
                    <li><a href="#building-with-llms">2. Building Applications with LLMs</a>
                        <ul>
                            <li><a href="#llm-architecture">2.1 Application Architecture</a></li>
                            <li><a href="#prompt-engineering">2.2 Prompt Engineering</a></li>
                            <li><a href="#context-management">2.3 Context Management</a></li>
                        </ul>
                    </li>
                    <li><a href="#chatbot-development">3. Creating AI Chatbots</a>
                        <ul>
                            <li><a href="#chatbot-basics">3.1 Chatbot Architecture</a></li>
                            <li><a href="#conversation-flow">3.2 Managing Conversation Flow</a></li>
                            <li><a href="#memory-state">3.3 Memory and State Management</a></li>
                        </ul>
                    </li>
                    <li><a href="#utta-system">4. Utah Teacher Training AI System</a>
                        <ul>
                            <li><a href="#system-overview">4.1 System Architecture</a></li>
                            <li><a href="#components">4.2 Core Components</a></li>
                            <li><a href="#implementation">4.3 Implementation Details</a></li>
                        </ul>
                    </li>
                    <li><a href="#getting-started">5. Getting Started</a>
                        <ul>
                            <li><a href="#setup">5.1 Setting Up Your Environment</a></li>
                            <li><a href="#first-run">5.2 Running Your First Session</a></li>
                            <li><a href="#customization">5.3 Customization Options</a></li>
                        </ul>
                    </li>
                </ul>
            </div>
        </aside>

        <main>
            <h1>Utah Elementary Teacher Training Assistant: A Complete Guide</h1>

            <div id="llm-fundamentals" class="section">
                <h2>Understanding Large Language Models (LLMs)</h2>

                <div id="what-are-llms" class="subsection">
                    <h3>What are LLMs?</h3>
                    <p>Large Language Models (LLMs) are advanced AI systems trained on vast amounts of text data. They represent a breakthrough in natural language processing, enabling:</p>
                    <ul>
                        <li>Natural language understanding and generation</li>
                        <li>Context-aware responses and reasoning</li>
                        <li>Task adaptation without specific training</li>
                        <li>Complex problem-solving and analysis</li>
                    </ul>

                    <div class="note">
                        <h4>Key Concepts</h4>
                        <ul>
                            <li><strong>Transformer Architecture:</strong> The neural network design that enables LLMs to process and understand language</li>
                            <li><strong>Self-Attention:</strong> Mechanism for understanding relationships between words in context</li>
                            <li><strong>Transfer Learning:</strong> Ability to apply knowledge to new tasks</li>
                            <li><strong>Few-Shot Learning:</strong> Capability to learn from minimal examples</li>
                        </ul>
                    </div>
                </div>

                <div id="llm-capabilities" class="subsection">
                    <h3>LLM Capabilities and Applications</h3>
                    <div class="example">
                        <h4>Core Capabilities</h4>
                        <ul>
                            <li>Text Generation and Completion</li>
                            <li>Question Answering and Analysis</li>
                            <li>Language Translation and Paraphrasing</li>
                            <li>Code Generation and Analysis</li>
                            <li>Content Summarization and Extraction</li>
                        </ul>
                    </div>

                    <div class="warning">
                        <h4>Limitations and Considerations</h4>
                        <ul>
                            <li>Potential for hallucinations or incorrect information</li>
                            <li>Need for proper prompt engineering</li>
                            <li>Resource requirements for larger models</li>
                            <li>Privacy and data security concerns</li>
                        </ul>
                    </div>
                </div>

                <div id="local-vs-api" class="subsection">
                    <h3>Local LLMs vs API Services</h3>
                    <div class="comparison">
                        <h4>Local LLMs (Like in UTTA)</h4>
                        <ul>
                            <li>✓ Complete privacy</li>
                            <li>✓ No API costs</li>
                            <li>✓ Customizable</li>
                            <li>✓ Offline operation</li>
                            <li>× Requires more computing power</li>
                            <li>× May have lower performance</li>
                        </ul>
                    </div>

                    <div class="example">
                        <h4>Popular Local LLMs for Educational Applications</h4>
                        <div class="note">
                            <h5>Minimum System Requirements</h5>
                            <ul>
                                <li>CPU: Any modern multi-core processor (2018 or newer)</li>
                                <li>RAM: 8GB minimum, 16GB recommended</li>
                                <li>Storage: 10GB free space</li>
                                <li>GPU: Optional - improves performance but not required</li>
                            </ul>
                        </div>

                        <div class="definition">
                            <h5>Ideal LLM Characteristics for Educational Chatbots</h5>
                            <p>For educational chatbot applications, the following characteristics are crucial:</p>
                            <ul>
                                <li><strong>Context Retention</strong>: Ability to maintain coherent conversations</li>
                                <li><strong>Response Consistency</strong>: Stable and reliable answers</li>
                                <li><strong>Instruction Following</strong>: Accurate responses to specific prompts</li>
                                <li><strong>Knowledge Accuracy</strong>: Reliable educational content delivery</li>
                            </ul>
                        </div>

                        <div class="example">
                            <h5>Best Models for Educational Chatbots</h5>
                            <ol>
                                <li><strong>For Basic Implementation (Limited Resources)</strong>
                                    <ul>
                                        <li>Phi-2 (2.7B)
                                            <ul>
                                                <li>Perfect for simple Q&A interactions</li>
                                                <li>Quick responses for basic tutoring</li>
                                                <li>Works well on standard laptops</li>
                                                <li>Good for pilot projects and testing</li>
                                            </ul>
                                        </li>
                                    </ul>
                                </li>
                                <li><strong>For Production Use (Recommended)</strong>
                                    <ul>
                                        <li>Mistral 7B
                                            <ul>
                                                <li>Excellent context understanding</li>
                                                <li>Strong conversational abilities</li>
                                                <li>Balanced performance and resource usage</li>
                                                <li>Ideal for most educational scenarios</li>
                                            </ul>
                                        </li>
                                        <li>ORCA 2
                                            <ul>
                                                <li>Specialized in educational interactions</li>
                                                <li>Better at complex explanations</li>
                                                <li>Strong pedagogical capabilities</li>
                                                <li>Good for advanced tutoring</li>
                                            </ul>
                                        </li>
                                    </ul>
                                </li>
                                <li><strong>For Advanced Features (High Resources)</strong>
                                    <ul>
                                        <li>Llama 2 (13B/70B)
                                            <ul>
                                                <li>Superior reasoning capabilities</li>
                                                <li>Better handling of complex topics</li>
                                                <li>More nuanced responses</li>
                                                <li>Requires significant computing power</li>
                                            </ul>
                                        </li>
                                    </ul>
                                </li>
                            </ol>
                        </div>

                        <div class="warning">
                            <h5>Important Considerations for Chatbot Implementation</h5>
                            <ul>
                                <li><strong>Response Time</strong>: Aim for under 2 seconds per response to maintain engagement</li>
                                <li><strong>Memory Usage</strong>: Consider concurrent users when choosing model size</li>
                                <li><strong>Conversation Length</strong>: Longer contexts require more capable models</li>
                                <li><strong>Error Handling</strong>: Larger models generally provide more reliable responses</li>
                            </ul>
                        </div>

                        <div class="definition">
                            <h5>Understanding Model Sizes</h5>
                            <p>Model size (in billions of parameters) affects both performance and resource requirements:</p>
                            <ul>
                                <li><strong>Small (1-3B)</strong>: Fast, efficient, good for basic tasks</li>
                                <li><strong>Medium (6-8B)</strong>: Balanced performance and resource usage</li>
                                <li><strong>Large (13B+)</strong>: Better quality but higher resource demands</li>
                            </ul>
                        </div>

                        <div class="example">
                            <h5>Key LLM Parameters and Capabilities</h5>

                            <div class="subsection">
                                <h6>Context Window Size</h6>
                                <ul>
                                    <li><strong>Phi-2</strong>: 2,048 tokens (~1,500 words)</li>
                                    <li><strong>Mistral 7B</strong>: 8,192 tokens (~6,000 words)</li>
                                    <li><strong>ORCA 2</strong>: 8,192 tokens (~6,000 words)</li>
                                    <li><strong>Llama 2</strong>: 4,096 tokens (~3,000 words)</li>
                                    <p><em>Note: Longer context windows allow for more detailed conversations and better memory of previous interactions.</em></p>
                                </ul>
                            </div>

                            <div class="subsection">
                                <h6>Adjustable Parameters for Chatbot Behavior</h6>
                                <ul>
                                    <li><strong>Temperature</strong> (Creativity vs Precision):
                                        <ul>
                                            <li>0.2-0.4: High precision, factual responses</li>
                                            <li>0.5-0.7: Balanced creativity and accuracy</li>
                                            <li>0.8-1.0: More creative, varied responses</li>
                                        </ul>
                                    </li>
                                    <li><strong>Top-P</strong> (Response Diversity):
                                        <ul>
                                            <li>0.1-0.3: Very focused, consistent</li>
                                            <li>0.4-0.6: Balanced variety</li>
                                            <li>0.7-0.9: More diverse responses</li>
                                        </ul>
                                    </li>
                                    <li><strong>Max Tokens</strong> (Response Length):
                                        <ul>
                                            <li>Short (50-100): Quick answers</li>
                                            <li>Medium (100-300): Detailed explanations</li>
                                            <li>Long (300+): In-depth discussions</li>
                                        </ul>
                                    </li>
                                </ul>
                            </div>

                            <div class="subsection">
                                <h6>Model-Specific Characteristics</h6>
                                <ul>
                                    <li><strong>Phi-2</strong>
                                        <ul>
                                            <li>Optimal Temperature: 0.3-0.5</li>
                                            <li>Best for: Precise, concise responses</li>
                                            <li>Token Processing: ~150 tokens/second on CPU</li>
                                            <li>Specialization: Code and technical content</li>
                                        </ul>
                                    </li>
                                    <li><strong>Mistral 7B</strong>
                                        <ul>
                                            <li>Optimal Temperature: 0.5-0.7</li>
                                            <li>Best for: Balanced interactions</li>
                                            <li>Token Processing: ~100 tokens/second on CPU</li>
                                            <li>Specialization: General-purpose teaching</li>
                                        </ul>
                                    </li>
                                    <li><strong>ORCA 2</strong>
                                        <ul>
                                            <li>Optimal Temperature: 0.6-0.8</li>
                                            <li>Best for: Educational explanations</li>
                                            <li>Token Processing: ~100 tokens/second on CPU</li>
                                            <li>Specialization: Step-by-step teaching</li>
                                        </ul>
                                    </li>
                                </ul>
                            </div>

                            <div class="warning">
                                <h6>Optimization Tips</h6>
                                <ul>
                                    <li><strong>For Basic Q&A</strong>:
                                        <ul>
                                            <li>Lower temperature (0.3)</li>
                                            <li>Shorter context window</li>
                                            <li>Faster response times</li>
                                        </ul>
                                    </li>
                                    <li><strong>For Teaching Interactions</strong>:
                                        <ul>
                                            <li>Medium temperature (0.6)</li>
                                            <li>Longer context retention</li>
                                            <li>Balance between creativity and accuracy</li>
                                        </ul>
                                    </li>
                                    <li><strong>For Complex Discussions</strong>:
                                        <ul>
                                            <li>Higher temperature (0.7-0.8)</li>
                                            <li>Maximum context window</li>
                                            <li>Focus on detailed explanations</li>
                                        </ul>
                                    </li>
                                </ul>
                            </div>
                        </div>

                        <ul>
                            <li><strong>Phi-2 (Recommended for Low-Resource Systems)</strong>
                                <ul>
                                    <li>Only 2.7B parameters - smallest but powerful</li>
                                    <li>Runs on CPU with just 6GB RAM</li>
                                    <li>4GB VRAM if using GPU</li>
                                    <li>Model size: ~1.5GB on disk</li>
                                    <li>Great for laptops and basic desktops</li>
                                    <li>Key Features:
                                        <ul>
                                            <li>Trained on high-quality educational data</li>
                                            <li>Excellent at explaining concepts</li>
                                            <li>Fast response times</li>
                                            <li>Good at code understanding and generation</li>
                                        </ul>
                                    </li>
                                    <li>Best Use Cases:
                                        <ul>
                                            <li>Basic tutoring interactions</li>
                                            <li>Quick concept explanations</li>
                                            <li>Resource-constrained environments</li>
                                        </ul>
                                    </li>
                                </ul>
                            </li>

                            <li><strong>Mistral 7B (Our Default Choice)</strong>
                                <ul>
                                    <li>7B parameters - balanced size/performance</li>
                                    <li>8GB RAM minimum for CPU inference</li>
                                    <li>6GB VRAM if using GPU</li>
                                    <li>Model size: ~4GB on disk</li>
                                    <li>Works well on mid-range hardware</li>
                                    <li>Key Features:
                                        <ul>
                                            <li>Sliding Window Attention for longer context</li>
                                            <li>Strong reasoning capabilities</li>
                                            <li>Excellent instruction following</li>
                                            <li>Good balance of speed and quality</li>
                                        </ul>
                                    </li>
                                    <li>Best Use Cases:
                                        <ul>
                                            <li>Complex teaching scenarios</li>
                                            <li>Multi-turn conversations</li>
                                            <li>Detailed explanations</li>
                                        </ul>
                                    </li>
                                </ul>
                            </li>

                            <li><strong>ORCA 2 (7B version)</strong>
                                <ul>
                                    <li>Similar requirements to Mistral 7B</li>
                                    <li>8GB RAM for CPU operation</li>
                                    <li>6GB VRAM for GPU acceleration</li>
                                    <li>Model size: ~4GB on disk</li>
                                    <li>Optimized for teaching tasks</li>
                                    <li>Key Features:
                                        <ul>
                                            <li>Fine-tuned specifically for instruction</li>
                                            <li>Enhanced reasoning capabilities</li>
                                            <li>Better at understanding context</li>
                                            <li>Strong at step-by-step explanations</li>
                                        </ul>
                                    </li>
                                    <li>Best Use Cases:
                                        <ul>
                                            <li>Detailed problem-solving</li>
                                            <li>Complex concept breakdowns</li>
                                            <li>Educational scaffolding</li>
                                        </ul>
                                    </li>
                                </ul>
                            </li>

                            <li><strong>Llama 2 (Multiple Sizes)</strong>
                                <ul>
                                    <li>7B version: Similar to Mistral requirements</li>
                                    <li>13B and 70B versions need more resources</li>
                                    <li>7B version recommended for most users</li>
                                    <li>Model size: 4GB-40GB depending on version</li>
                                    <li>Available Versions:
                                        <ul>
                                            <li>7B: Good balance for most uses</li>
                                            <li>13B: Better quality, needs 12GB+ VRAM</li>
                                            <li>70B: Best quality, needs 32GB+ VRAM</li>
                                        </ul>
                                    </li>
                                    <li>Key Features:
                                        <ul>
                                            <li>Extensive pre-training</li>
                                            <li>Strong safety features</li>
                                            <li>Good at following complex instructions</li>
                                            <li>Commercial use allowed</li>
                                        </ul>
                                    </li>
                                </ul>
                            </li>
                        </ul>

                        <div class="note">
                            <h5>Performance Comparison</h5>
                            <ul>
                                <li><strong>Response Speed (CPU only)</strong>:
                                    <ul>
                                        <li>Phi-2: Fastest (0.5-1 second)</li>
                                        <li>Mistral 7B: Moderate (1-2 seconds)</li>
                                        <li>ORCA 2: Similar to Mistral</li>
                                        <li>Llama 2: Varies by size (1-3 seconds)</li>
                                    </ul>
                                </li>
                                <li><strong>Response Quality</strong>:
                                    <ul>
                                        <li>Phi-2: Good for basic interactions</li>
                                        <li>Mistral 7B: Excellent all-around</li>
                                        <li>ORCA 2: Best for teaching tasks</li>
                                        <li>Llama 2: Scales with model size</li>
                                    </ul>
                                </li>
                            </ul>
                        </div>

                        <div class="warning">
                            <p><strong>Performance Note:</strong> CPU-only operation is possible but slower. For optimal performance in educational settings where quick responses are important, a GPU with at least 6GB VRAM is recommended but not required.</p>
                        </div>

                        <div class="note">
                            <p><strong>Recommendation:</strong> For resource-constrained environments (like basic laptops or older desktops), start with Phi-2. For better performance on standard hardware, use our default Mistral 7B model. All models can
                                run on CPU-only systems, but inference will be slower.</p>
                        </div>
                    </div>
                </div>
            </div>

            <div id="building-with-llms" class="section">
                <h2>Building AI Applications with LLMs</h2>

                <div id="application-architecture" class="subsection">
                    <h3>Application Architecture</h3>
                    <div class="diagram">
                        <h4>Core Components</h4>
                        <div class="component-grid">
                            <div class="component">
                                <h5>LLM Interface</h5>
                                <p>Handles communication with the language model</p>
                            </div>
                            <div class="component">
                                <h5>Context Manager</h5>
                                <p>Maintains conversation state and history</p>
                            </div>
                            <div class="component">
                                <h5>Knowledge Base</h5>
                                <p>Stores domain-specific information</p>
                            </div>
                            <div class="component">
                                <h5>Response Handler</h5>
                                <p>Processes and formats model outputs</p>
                            </div>
                        </div>
                    </div>
                </div>

                <div id="ai-agents" class="subsection">
                    <h3>Creating AI Agents</h3>
                    <div class="example">
                        <h4>Agent Components</h4>
                        <pre>
class AIAgent:
    def __init__(self):
        self.llm = LLMInterface()
        self.memory = ContextManager()
        self.knowledge = KnowledgeBase()
        
    def process_input(self, user_input):
        context = self.memory.get_context()
        knowledge = self.knowledge.search(user_input)
        response = self.llm.generate(
            prompt=user_input,
            context=context,
            knowledge=knowledge
        )
        self.memory.update(user_input, response)
        return response</pre>
                    </div>
                </div>
            </div>

            <div id="chatbot-development" class="section">
                <h2>Building Educational Chatbots</h2>

                <div id="chatbot-architecture" class="subsection">
                    <h3>Chatbot Architecture</h3>
                    <div class="diagram">
                        <h4>Essential Components</h4>
                        <div class="component-grid">
                            <div class="component">
                                <h5>Dialog Manager</h5>
                                <p>Controls conversation flow</p>
                            </div>
                            <div class="component">
                                <h5>State Tracker</h5>
                                <p>Monitors interaction progress</p>
                            </div>
                            <div class="component">
                                <h5>Response Generator</h5>
                                <p>Creates contextual responses</p>
                            </div>
                        </div>
                    </div>
                </div>

                <div id="educational-features" class="subsection">
                    <h3>Educational Features</h3>
                    <div class="example">
                        <h4>Key Capabilities</h4>
                        <ul>
                            <li>Personalized Learning Paths</li>
                            <li>Progress Tracking</li>
                            <li>Adaptive Feedback</li>
                            <li>Multi-modal Interactions</li>
                        </ul>
                    </div>
                </div>
            </div>

            <div id="utta-system" class="section">
                <h2>Utah Teacher Training AI System</h2>

                <div id="system-overview" class="subsection">
                    <h3>System Architecture</h3>
                    <div class="diagram">
                        <h4>Core Components</h4>
                        <div class="component-grid">
                            <div class="component">
                                <h5>TeacherTrainingAgent</h5>
                                <p>Main simulation controller</p>
                                <ul>
                                    <li>Manages training scenarios</li>
                                    <li>Coordinates component interactions</li>
                                    <li>Tracks training progress</li>
                                </ul>
                            </div>
                            <div class="component">
                                <h5>PedagogicalKnowledgeManager</h5>
                                <p>Educational resource manager</p>
                                <ul>
                                    <li>Stores teaching strategies</li>
                                    <li>Processes educational content</li>
                                    <li>Provides contextual recommendations</li>
                                </ul>
                            </div>
                            <div class="component">
                                <h5>PedagogicalLanguageProcessor</h5>
                                <p>Natural language handler</p>
                                <ul>
                                    <li>Analyzes teaching responses</li>
                                    <li>Generates student reactions</li>
                                    <li>Evaluates teaching effectiveness</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>

                <div id="implementation-details" class="subsection">
                    <h3>Implementation Details</h3>
                    <div class="example">
                        <h4>Key Features</h4>
                        <pre>
# Initialize the system
agent = TeacherTrainingAgent()
knowledge = PedagogicalKnowledgeManager()
processor = PedagogicalLanguageProcessor()

# Generate teaching scenario
scenario = agent.generate_scenario(
    subject="math",
    difficulty="multiplication",
    student_profile={
        "learning_style": "visual",
        "attention_span": 0.7,
        "current_challenges": ["number sense"]
    }
)

# Process teacher's response
response = processor.analyze_teaching_response(
    teacher_input="Let's use counters to understand multiplication",
    context=scenario
)

# Generate student reaction
reaction = processor.generate_student_reaction(
    context=scenario,
    teacher_response=response,
    effectiveness=0.85
)</pre>
                    </div>
                </div>

                <div id="usage-workflow" class="subsection">
                    <h3>Usage Workflow</h3>
                    <ol>
                        <li><strong>Setup Phase</strong>
                            <ul>
                                <li>Initialize system components</li>
                                <li>Load teaching knowledge base</li>
                                <li>Configure student profiles</li>
                            </ul>
                        </li>
                        <li><strong>Training Session</strong>
                            <ul>
                                <li>Generate teaching scenario</li>
                                <li>Present student situation</li>
                                <li>Process teacher responses</li>
                                <li>Provide immediate feedback</li>
                            </ul>
                        </li>
                        <li><strong>Analysis Phase</strong>
                            <ul>
                                <li>Evaluate teaching effectiveness</li>
                                <li>Generate detailed feedback</li>
                                <li>Track progress over time</li>
                            </ul>
                        </li>
                    </ol>
                </div>
            </div>

            <div id="getting-started" class="section">
                <h2>Getting Started</h2>

                <div id="setup" class="subsection">
                    <h3>Setting Up Your Environment</h3>
                    <div class="code-example">
                        <h4>Installation Steps</h4>
                        <pre>
# Clone the repository
git clone https://github.com/UVU-AI-Innovate/UTTA.git

# Install dependencies
pip install -r requirements.txt

# Download the LLM model
ollama pull mistral

# Start the application
python terminal_app.py</pre>
                    </div>
                </div>

                <div id="first-run" class="subsection">
                    <h3>Running Your First Session</h3>
                    <p>Follow these steps to start your first training session:</p>
                    <ol>
                        <li>Initialize the training agent</li>
                        <li>Set up your teacher profile</li>
                        <li>Select a subject area</li>
                        <li>Respond to the generated scenario</li>
                        <li>Review feedback and student reactions</li>
                    </ol>
                </div>

                <div id="customization" class="subsection">
                    <h3>Customization Options</h3>
                    <ul>
                        <li>Modify teaching scenarios</li>
                        <li>Adjust student profiles</li>
                        <li>Add custom teaching strategies</li>
                        <li>Configure evaluation criteria</li>
                    </ul>
                </div>
            </div>
        </main>
    </div>

    <a href="#" class="back-to-top">↑ Back to Top</a>

    <script>
        // Toggle Table of Contents
        function toggleTOC() {
            const toc = document.querySelector('.toc');
            toc.classList.toggle('show');
        }

        // Back to Top button visibility
        window.onscroll = function() {
            const backToTop = document.querySelector('.back-to-top');
            if (document.body.scrollTop > 500 || document.documentElement.scrollTop > 500) {
                backToTop.classList.add('visible');
            } else {
                backToTop.classList.remove('visible');
            }
        };

        // Smooth scrolling for anchor links
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function(e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({
                        behavior: 'smooth'
                    });
                }
            });
        });
    </script>
</body>

</html>